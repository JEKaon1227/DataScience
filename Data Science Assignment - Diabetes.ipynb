{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BACS3013 Data Science Assignment - Diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. choose model class\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.stats import ttest_ind\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.naive_bayes import GaussianNB "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('diabetes_data_upload.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['class'])  # Features (excluding the target variable)\n",
    "y = df['class']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().any().any() # check the missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head() # print the data from head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail() # print the data from tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the column variable\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of rows and columns\n",
    "rows = len(df.axes[0])\n",
    "cols = len(df.axes[1])\n",
    "  \n",
    "# Print the number of rows and columns\n",
    "print(\"Number of Rows: \" + str(rows))\n",
    "print(\"Number of Columns: \" + str(cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test if missing value exist\n",
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info() # print the information of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Mapping for Gender\n",
    "df['Gender'] = df['Gender'].map({'Male': 0, 'Female': 1})\n",
    "\n",
    "# Mapping for Yes/No Data\n",
    "binary_columns = ['Polyuria', 'Polydipsia', 'sudden weight loss', 'weakness', 'Polyphagia', 'Genital thrush',\n",
    "                  'visual blurring', 'Itching', 'Irritability', 'delayed healing', 'partial paresis', 'muscle stiffness',\n",
    "                  'Alopecia', 'Obesity']\n",
    "\n",
    "for column in binary_columns:\n",
    "    df[column] = df[column].map({'No': 0, 'Yes': 1})\n",
    "\n",
    "# Mapping for Positive/Negative Data\n",
    "df['class'] = df['class'].map({'Negative': 0, 'Positive': 1})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the correlation of the class\n",
    "correlation_with_class = df.corr()['class'].abs().sort_values(ascending=False)\n",
    "\n",
    "print(correlation_with_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the heatmap\n",
    "plt.subplots(figsize=(20,15))\n",
    "sns.heatmap(df.corr(), cmap=\"YlGnBu\", annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the description of the data\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values = []\n",
    "for column in df.drop(columns=['class']):\n",
    "    feature_positive = df[df['class'] == 1][column]\n",
    "    feature_negative = df[df['class'] == 0][column]\n",
    "    _, p_value = ttest_ind(feature_positive, feature_negative)\n",
    "    p_values.append((column, p_value))\n",
    "\n",
    "# Select columns with p-value less than a significance level (e.g., 0.05)\n",
    "significant_columns = [col for col, p_value in p_values if p_value < 0.05]\n",
    "\n",
    "# Keep only the significant columns\n",
    "df = df[['class'] + significant_columns]\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning And Remove Outliers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data Into Training Set and Testing Set,  Normalizing Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbours (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consider the labels of the 5 nearest data points to a given input when making a prediction.\n",
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "\n",
    "# Fit model to data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Predict on new data\n",
    "knn_pred = knn.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracyScore = accuracy_score(y_test, knn_pred)\n",
    "print(\"Accuracy Score:\", accuracyScore)\n",
    "\n",
    "roundScore = round(accuracy_score(y_test, knn_pred)*100, 3)\n",
    "print('Accuracy Score: ', roundScore)\n",
    "\n",
    "# Mean Square Error\n",
    "mse = mean_squared_error(y_test, knn_pred)\n",
    "rmse = math.sqrt(mse)\n",
    "print('RMSE: %f' % rmse)\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, knn_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Classification Report\n",
    "class_report = classification_report(y_test, knn_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the heatmap plot     \n",
    "fig, ax = plt.subplots(figsize=(10,10)) \n",
    "\n",
    "mat = confusion_matrix(y_test, knn_pred)  #target variable and prediction\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,cmap=\"YlGnBu\",\n",
    "            xticklabels=[\"Predicted 0\", \"Predicted 1\"],\n",
    "            yticklabels=[\"True 0\", \"True 1\"])\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel('True Label')\n",
    "plt.ylabel('Predicted Label');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine (SVM / SVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the linear regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=[\"Predicted 0\", \"Predicted 1\"],\n",
    "            yticklabels=[\"True 0\", \"True 1\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
